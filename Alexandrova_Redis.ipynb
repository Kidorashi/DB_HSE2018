{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть корпус текстов. В нем есть выделенные при помощи каких-то мер устойчевые словосочетания. Надо организовать хранение и поиск текстов и словосочетаний. То есть, например, пользователь вводит сочетание, а мы ему показываем фрагменты текстов с ним (например, предложение), плюс метаинформацию по тексту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r.set('a', 'c') - новый объект 'ключ - значение'\n",
    "r.get('a') - получить значение ключа 'а'\n",
    "r.mget('a', 'c') - получить значения ключей 'а' и 'с'\n",
    "r.mget('a', 'c') - получить значения ключей 'а' и 'с'\n",
    "r.append(\"a\", \"c\") - добавить значение 'с' в ключ 'а'\n",
    "r.hset(key, value, number) - key[value] = number\n",
    "r.hmset(key, {value1:number1, value2:number2})\n",
    "r.hget(key, vlue) > number\n",
    "r.hget(key) - всё"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redis in c:\\users\\1\\anaconda3\\lib\\site-packages (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk import tokenize\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "punct = punctuation+'«»―…“”*№–'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    if type(text) is str:\n",
    "        words = [word.strip(punct) for word in text.lower().split()]\n",
    "        words = [morph.parse(word)[0].normal_form for word in words if word]\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        for idx, sent in enumerate(text):\n",
    "            words = [word.strip(punct) for word in sent.lower().split()]\n",
    "            words = [morph.parse(word)[0].normal_form for word in words if word]\n",
    "            text[idx] = ' '.join(words)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = redis.StrictRedis(host='localhost', port=6379, db=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Состав БД"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) хранение текстов и метаданных;\n",
    "hmset('text:int', {'t_id':t_id, 'test':text, 'norm_text':norm_tex, 'title':title, 'author':author, 'year':year})\n",
    "2) хранение фраз и значений;\n",
    "hmset('phrase', {'p_id':p_id, 'meaning':meaning})\n",
    "3) хранение соответствий фраз и текстов/предложений;\n",
    "hset(where, 'p_id':'{t_id:[sents], t_id:[sents]}')\n",
    "4) счётчик текстов и фраз;\n",
    "hmset('maxes', {'t_max':t_id_last, 'p_max':p_id_last'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Положим в БД данные для экспериментов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные сейчас введу вручную, мелкими глупыми функциями, чтобы не заморачиваться. Аналогичные этим будут использоватья ниже, но я их буду переписывать, чтобы было красивее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Положим пару текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('test_texts.txt', encoding = 'UTF-8') as f:\n",
    "    texts = f.read()\n",
    "\n",
    "with open ('test_texts.txt', encoding = 'UTF-8') as f:\n",
    "    norm_texts = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = texts.split('\\n\\n')\n",
    "norm_texts = norm_texts.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_text = []\n",
    "for n in range(len(texts)):\n",
    "    texts[n] = texts[n].replace('\\ufeff', '').replace('…', '.')\n",
    "    texts[n] = texts[n].split('\\n')\n",
    "    norm_texts[n] = norm_texts[n].replace('\\ufeff', '').replace('…', '.')\n",
    "    norm_texts[n] = norm_texts[n].split('\\n')\n",
    "    texts[n][0] = tokenize.sent_tokenize(texts[n][0])\n",
    "    norm_text.append(normalize(tokenize.sent_tokenize(norm_texts[n][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['― Бедные.',\n",
       "  '― Настя совсем расстроилась.',\n",
       "  '― Да уж, им не позавидуешь, ― согласился папа.',\n",
       "  '― Но не надо вешать нос!',\n",
       "  'Разве мы с вами нашего Барсика не на улице нашли?',\n",
       "  'Даже с бездомными кошками случаются настоящие чудеса.',\n",
       "  'Однако что же мы стоим на морозе?'],\n",
       " 'Екатерина Каретникова',\n",
       " 'Зимняя сказка ',\n",
       " '2011']"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['бедный',\n",
       " 'настя совсем расстроиться',\n",
       " 'да уж имя не позавидовать согласиться папа',\n",
       " 'но не надо вешать нос',\n",
       " 'разве мы с вы наш барсик не на улица найти',\n",
       " 'даже с бездомный кошка случаться настоящий чудо',\n",
       " 'однако что же мы стоять на мороз']"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2011'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_texts(texts, norm_text):\n",
    "    for i in range(len(texts)):\n",
    "        #i - t_id\n",
    "        t = 'text:'+str(i)\n",
    "        r.hmset(t, {'t_id':str(i), 'text':str(texts[i][0]), 'norm_text':str(norm_text[i]), 'title':texts[i][2], \n",
    "                       'author':texts[i][1], 'year':texts[i][3]})\n",
    "        r.hmset('maxes', {'t_max':str(i), 'p_max':'None'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_texts(texts, norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Зимняя сказка '"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hget('text:0', 'title').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'p_max': b'None', b't_max': b'11'}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('maxes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Положим пару фраз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('text_phrases.txt', encoding = 'UTF-8') as f:\n",
    "    phrases = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases= phrases.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['бить баклуши\\nлениться',\n",
       " 'кот наплакал\\nочень мало',\n",
       " 'ахилесова пята\\nочень мало',\n",
       " 'бабье лето\\nтёплые дни ранней осени',\n",
       " 'бальзам на душу\\nчто-то, что успокаивает тревогу',\n",
       " 'битый час\\nочень долго']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ph = []\n",
    "mea = []\n",
    "for p in phrases:\n",
    "    ph.append(p.split('\\n')[0])\n",
    "    mea.append(p.split('\\n')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('бить баклуши', 'лениться')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph[0], mea[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_phs(ph, mea):\n",
    "    for i in range(len(ph)):\n",
    "        r.hmset(ph[i], {'p_id':str(i), 'meaning':mea[i]})\n",
    "    r.hmset('maxes', {'p_max':str(i)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "put_phs(ph, mea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'meaning': b'\\xd0\\xbe\\xd1\\x87\\xd0\\xb5\\xd0\\xbd\\xd1\\x8c \\xd0\\xb4\\xd0\\xbe\\xd0\\xbb\\xd0\\xb3\\xd0\\xbe',\n",
       " b'p_id': b'5'}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('битый час')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'p_max': b'5', b't_max': b'11'}"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('maxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подходит для дальнейшего использования\n",
    "def get_where(phrase):\n",
    "    norm_phrase =  normalize(phrase)\n",
    "    dic = {}\n",
    "    l = int(r.hget('maxes', 't_max').decode('utf-8')) #количество текстов\n",
    "    for i in range(l):\n",
    "        sents = []\n",
    "        t = 'text:' + str(i)\n",
    "        if r.exists(t) == 1:\n",
    "            norm_sents = r.hget(t, 'norm_text').decode('utf-8').strip(\"[]\").split(', ')\n",
    "            for s in range(len(norm_sents)):\n",
    "                if norm_phrase in norm_sents[s]:\n",
    "                    sents.append(str(s))\n",
    "            if sents != []:\n",
    "                dic[i] = sents\n",
    "        else:\n",
    "            continue\n",
    "    dic = json.dumps(dic)\n",
    "    if dic != '{}':\n",
    "        p_id = r.hget(phrase, 'p_id').decode('utf-8')\n",
    "        r.hset('where', p_id, dic)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.exists('text:22') ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in ph:\n",
    "    get_where(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'0': b'{\"10\": [\"0\"]}',\n",
       " b'1': b'{\"8\": [\"3\"], \"9\": [\"3\"]}',\n",
       " b'3': b'{\"6\": [\"4\"], \"7\": [\"3\"]}',\n",
       " b'4': b'{\"4\": [\"3\"], \"5\": [\"3\"]}'}"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('where')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск по выражению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_info(all_info):\n",
    "    print(all_info[0] + '\\n')\n",
    "    print('Название текста: ' + ''.join(all_info[1]))\n",
    "    print('Автор текста: ' + all_info[2])\n",
    "    print('Год создания текста: ' + all_info[3] + '\\n')\n",
    "    print('~~~')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(t_id):\n",
    "    all_info = []\n",
    "    t_id = 'text:'+t_id\n",
    "    te = r.hget('text:1', 'text').decode('utf-8').strip(\"[']\").replace(\"', '\", \" \")\n",
    "    ti = r.hget(t_id, 'title').decode('utf-8')\n",
    "    au = r.hget(t_id, 'author').decode('utf-8')\n",
    "    ye = r.hget(t_id, 'year').decode('utf-8')\n",
    "    all_info.extend([te, ti, au, ye])\n",
    "    print_info(all_info)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_in_base(phrase):\n",
    "    if r.exists(phrase) is 1:\n",
    "        meaning = r.hget(phrase, 'meaning').decode('utf-8')\n",
    "        p_id = r.hget(phrase, 'p_id').decode('utf-8')\n",
    "        print\n",
    "        print('Значение: ' + meaning + '\\n')\n",
    "        if r.hexists('where', p_id) is True:\n",
    "            d = json.loads(r.hget('where', p_id).decode('utf-8'))\n",
    "            where_p = list(d.keys())\n",
    "            for t_id in where_p:\n",
    "                get_info(t_id)\n",
    "        else:\n",
    "            print('К сожалению, примеров нет.')\n",
    "    else:\n",
    "        print('Такого выражения в базе нет.')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение: очень мало\n",
      "\n",
      "― Вообще ― многое поздно. Я не ответил, потому что это замечание не предполагало ответа. Собственно, почти всё было уже ясно. ― Не вешайте нос, прапорщик, ― произнёс я совершенно механически. Так военный хирург в приёмном покое раз за разом привычно говорит своим искалеченным пациентам что-нибудь вроде: «Мы ещё с вами водки выпьем, лейтенант» . ― Я не вешаю, ― живо возразил Дыбовский. ― Просто надо же реалистично смотреть на вещи.\n",
      "\n",
      "Название текста: Многоточие сборки\n",
      "Автор текста: Ю. И. Андреева\n",
      "Год создания текста: 2009\n",
      "\n",
      "~~~\n",
      "― Вообще ― многое поздно. Я не ответил, потому что это замечание не предполагало ответа. Собственно, почти всё было уже ясно. ― Не вешайте нос, прапорщик, ― произнёс я совершенно механически. Так военный хирург в приёмном покое раз за разом привычно говорит своим искалеченным пациентам что-нибудь вроде: «Мы ещё с вами водки выпьем, лейтенант» . ― Я не вешаю, ― живо возразил Дыбовский. ― Просто надо же реалистично смотреть на вещи.\n",
      "\n",
      "Название текста: Прощеное воскресенье\n",
      "Автор текста: Вацлав Михальский\n",
      "Год создания текста: 2009\n",
      "\n",
      "~~~\n"
     ]
    }
   ],
   "source": [
    "search_in_base('кот наплакал')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение: очень мало\n",
      "\n",
      "К сожалению, примеров нет.\n"
     ]
    }
   ],
   "source": [
    "search_in_base('ахилесова пята')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Такого выражения в базе нет.\n"
     ]
    }
   ],
   "source": [
    "search_in_base('второе дыхание')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление фразы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_phrase(phrase, meaning):\n",
    "    if r.exists(phrase) is 1:\n",
    "        print('Такое выражение уже есть в базе.')\n",
    "    else:\n",
    "        new_id = str(int(r.hget('maxes', 'p_max').decode('utf-8')) + 1)\n",
    "        r.hmset('maxes', {'p_max':new_id})\n",
    "        r.hmset(phrase, {'p_id':new_id, 'meaning':meaning})\n",
    "        get_where(phrase)\n",
    "        print('Выражение успешно добавлено!')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Такое выражение уже есть в базе.\n"
     ]
    }
   ],
   "source": [
    "my_phrase = 'бить баклуши'\n",
    "mea = 'лениться'\n",
    "add_phrase(my_phrase, mea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выражение успешно добавлено!\n"
     ]
    }
   ],
   "source": [
    "my_phrase = 'белая ворона'\n",
    "mea = 'непохожий на других'\n",
    "add_phrase(my_phrase, mea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'meaning': b'\\xd0\\xbd\\xd0\\xb5\\xd0\\xbf\\xd0\\xbe\\xd1\\x85\\xd0\\xbe\\xd0\\xb6\\xd0\\xb8\\xd0\\xb9 \\xd0\\xbd\\xd0\\xb0 \\xd0\\xb4\\xd1\\x80\\xd1\\x83\\xd0\\xb3\\xd0\\xb8\\xd1\\x85',\n",
       " b'p_id': b'8'}"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('белая ворона')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление фразы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_phrase(phrase):\n",
    "    i_d = r.hget(phrase, 'p_id')\n",
    "    r.hdel('where', i_d)\n",
    "    r.delete(phrase)\n",
    "    print('Выражение удалено из базы.')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.exists('белая ворона')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выражение удалено из базы.\n"
     ]
    }
   ],
   "source": [
    "delete_phrase('белая ворона')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.exists('белая ворона')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('new_text.txt', encoding = 'UTF-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "auth = 'Юрий Трифонов'\n",
    "title = 'Предварительные итоги'\n",
    "year = '1970'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_sents(all_phrases, t_id):\n",
    "    t = 'text:' + str(t_id)\n",
    "    norm_sents = r.hget(t, 'norm_text').decode('utf-8').strip(\"[]\").split(', ')\n",
    "    for phrase in all_phrases:\n",
    "        sents = []\n",
    "        norm_phrase =  normalize(phrase)\n",
    "        p_id = r.hget(phrase, 'p_id').decode('utf-8')\n",
    "        if r.hexists('where', p_id):\n",
    "            dict_where = json.loads(r.hget('where', p_id))\n",
    "        else:\n",
    "            dict_where = {}\n",
    "        for s in range(len(norm_sents)):\n",
    "            if norm_phrase in norm_sents[s]:\n",
    "                sents.append(str(s))\n",
    "        if sents != []:\n",
    "            dict_where[t_id] = sents\n",
    "        dict_where = json.dumps(dict_where)\n",
    "        if dict_where != '{}':\n",
    "            r.hset('where', p_id, dict_where)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_phrases():\n",
    "    all_phrases = []\n",
    "    for a in r.keys():\n",
    "        a = a.decode('utf-8')\n",
    "        if 'text' not in a and 'maxes'not in a and 'where' not in a:\n",
    "            all_phrases.append(a)\n",
    "    return(all_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_text(text, auth, title, year):\n",
    "    text = text.replace('…', '.').strip('\\ufeff\\n')\n",
    "    text = tokenize.sent_tokenize(text)\n",
    "    norm_text = normalize(text)\n",
    "    new_id = str(int(r.hget('maxes', 't_max').decode('utf-8')) + 1)\n",
    "    t = 'text:'+new_id\n",
    "    r.hmset(t, {'t_id':new_id, 'text':str(text), 'norm_text':str(norm_text), 'title':title, 'author':auth, 'year':year})\n",
    "    all_phrases = det_all_phrases()\n",
    "    add_sents(all_phrases, new_id)\n",
    "    r.hmset('maxes', {'t_max':new_id})\n",
    "    print('Новый текст добавлен.')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'0': b'{\"10\": [\"0\"], \"11\": [\"3\"]}',\n",
       " b'1': b'{\"8\": [\"3\"], \"9\": [\"3\"]}',\n",
       " b'3': b'{\"6\": [\"4\"], \"7\": [\"3\"]}',\n",
       " b'4': b'{\"4\": [\"3\"], \"5\": [\"3\"]}'}"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('where')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новый текст добавлен.\n"
     ]
    }
   ],
   "source": [
    "add_text(text, auth, title, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'0': b'{\"10\": [\"0\"], \"11\": [\"3\"]}',\n",
       " b'1': b'{\"8\": [\"3\"], \"9\": [\"3\"]}',\n",
       " b'3': b'{\"6\": [\"4\"], \"7\": [\"3\"]}',\n",
       " b'4': b'{\"4\": [\"3\"], \"5\": [\"3\"]}',\n",
       " b'5': b'{\"12\": [\"0\"]}'}"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('where')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_one_text(title):\n",
    "    for a in r.keys():\n",
    "        a = a.decode('utf-8')\n",
    "        if 'text' in a and r.hget(a, 'title').decode('utf-8') == title:\n",
    "            return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = {\"hello\":\"gdbye\"}\n",
    "a = lol.pop(\"hello\")\n",
    "lol == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_where(t_id):\n",
    "    all_phrases = get_all_phrases()\n",
    "    for phrase in all_phrases:\n",
    "        p_id = r.hget(phrase, 'p_id').decode('utf-8')\n",
    "        if r.hexists('where', p_id):\n",
    "            dict_where = json.loads(r.hget('where', p_id))\n",
    "            try:\n",
    "                a = dict_where.pop(t_id)\n",
    "            except:\n",
    "                continue\n",
    "            if dict_where != {}:\n",
    "                dict_where = json.dumps(dict_where)\n",
    "                r.hset('where', p_id, dict_where)\n",
    "            else:\n",
    "                r.hdel('where', p_id)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_text(title):\n",
    "    text = get_one_text(title)\n",
    "    t_id = r.hget(text, 't_id')\n",
    "    delete_where(t_id)\n",
    "    r.delete(text)\n",
    "    print('Текст удалён.')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'0': b'{\"10\": [\"0\"], \"11\": [\"3\"]}',\n",
       " b'1': b'{\"8\": [\"3\"], \"9\": [\"3\"]}',\n",
       " b'3': b'{\"6\": [\"4\"], \"7\": [\"3\"]}',\n",
       " b'4': b'{\"4\": [\"3\"], \"5\": [\"3\"]}',\n",
       " b'5': b'{\"12\": [\"0\"]}'}"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('where')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст удалён.\n"
     ]
    }
   ],
   "source": [
    "delete_text(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'0': b'{\"10\": [\"0\"], \"11\": [\"3\"]}',\n",
       " b'1': b'{\"8\": [\"3\"], \"9\": [\"3\"]}',\n",
       " b'3': b'{\"6\": [\"4\"], \"7\": [\"3\"]}',\n",
       " b'4': b'{\"4\": [\"3\"], \"5\": [\"3\"]}'}"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hgetall('where')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Редактирование текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_typ_text(typ, data):\n",
    "    for a in r.keys():\n",
    "        a = a.decode('utf-8')\n",
    "        if 'text' in a and r.hget(a, typ).decode('utf-8') == data:\n",
    "            return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change(typ, data, new_data):\n",
    "    text = get_typ_text(typ, data)\n",
    "    r.hmset(text, {typ:new_data})\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Повесть о жизни'"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hget('text:11', 'title').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change('title', 'Повесть о жизни', 'Повесть о смерти')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Повесть о смерти'"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.hget('text:11', 'title').decode('utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
